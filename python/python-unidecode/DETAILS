            MODULE=python-unidecode
           VERSION=1.0.23
            SOURCE=unidecode-$VERSION.tar.gz
  SOURCE_DIRECTORY=$BUILD_DIRECTORY/unidecode-unidecode-$VERSION
        SOURCE_URL=https://github.com/avian2/unidecode/archive/
        SOURCE_VFY=sha256:82d9eb75da926badecfec345cdd485d464e6a85a24922c893a84f9ee0089d3cf
          WEB_SITE=https://github.com/avian2/unidecode/
              TYPE=python3
           ENTERED=20180226
           UPDATED=20181121
             SHORT="ASCII transliterations of Unicode text"

cat << EOF
Unidecode provides a middle road: function unidecode() takes Unicode data and
tries to represent it in ASCII characters (i.e., the universally displayable
characters between 0x00 and 0x7F), where the compromises taken when mapping
between two character sets are chosen to be near what a human with a US
keyboard would choose.
The quality of resulting ASCII representation varies. For languages of western
origin it should be between perfect and good. On the other hand transliteration
(i.e., conveying, in Roman letters, the pronunciation expressed by the text in
some other writing system) of languages like Chinese, Japanese or Korean is a
very complex issue and this library does not even attempt to address it. It
draws the line at context-free character-by-character mapping. So a good rule
of thumb is that the further the script you are transliterating is from Latin
alphabet, the worse the transliteration will be.
EOF
